Knowledge_template: |
  [Role]
  당신은 대규모 언어 모델이 생성한 답변의 '사실 정확성'을 평가하는 전문가입니다.
  
  [reference_data]가 제공된다면 이를 **최우선 기준**으로 삼아 [응답 프롬프트]의 품질을 평가하세요.  
  reference_data가 없을 경우, 일반적으로 알려진 사실/지식에 기반해 평가하세요.

  [평가기준]
  다음 기준에 따라 각 항목을 0~10 범위에서 점수화하세요.  
    1. 사실 정확성 (가중치 0.30) : 제시된 정보가 실제 사실과 얼마나 일치하는가  
    2. 세부 정보 신뢰도 (가중치 0.15) : 날짜, 수치, 고유명사 등의 정확성  
    3. 근거 제시 여부 (가중치 0.15) : 정보에 대한 출처나 논리적 근거가 명확한가  
    4. 오정보 여부 (가중치 0.20) : 잘못되거나 왜곡된 정보가 없는가  
    5. 완전성 (가중치 0.20) : 질문에 필요한 핵심 정보를 빠짐없이 제공했는가  

  [총점 산출 방식]  
  - 각 항목의 점수를 0~10 사이 값으로 매기고, 가중치를 곱합니다.  
  - 모든 항목의 "(점수 × 가중치)" 합을 "(가중치 총합)"으로 나눕니다.  
  - 이 값을 다시 10으로 나누어 0~1 범위로 정규화합니다.  
  - 최종 총점은 **0~1 범위 소수점 2자리**로 표시하세요.  
  - 예: 총점 = (Σ(점수 × 가중치) / Σ(가중치)) / 10  

  [reference_data]
  {{reference_data}}

  [요청 프롬프트]
  {{prompt}}
  
  [응답 프롬프트]
  {{response}}


  [평가 결과]
  평가 결과는 반드시 아래와 같은 **JSON** 양식으로 제공해줘야 합니다.
  양식은 절대 변경하지 마세요.
  ```json
  {
    "사실 정확성": <0-10 점수>, 
    "세부 정보 신뢰도": <0-10 점수>,
    "근거 제시 여부": <0-10 점수>,
    "오정보 여부": <0-10 점수>,
    "완전성": <0-10 점수>,
    "총점" : <0-1범위 소수점 2자리, 가중 평균>,
    "평가의견" : <brief reason summary>
  }
  ```